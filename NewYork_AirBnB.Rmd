---
title: <center><b> New York AirBnB <br> Regression Analysis, Visualization and Modelling </b></center>
subtitle: <center><b> Price Prediction for AirBnbs in New York </b></center>
author: <center> Sayak Chakraborty | Samreen Zehra | Niharika Gupta | Rohit Thakur </center>
output:
  html_document: 
    code_folding: show
always_allow_html: yes
---

<style>
body {
        text-align: justify;
        font-family: "Bookman", Bookman;
        font-size: 15pt;
     }
</style>

<style>

h1 {
  color: #2100A4
  font-family: Bookman;
}

h2 {
  color: #2100A4;
  font-family: Bookman;
}

h3 {
  color: #2100A4;
  font-family: Bookman;
}

h4 {
  color: #2100A4;
  font-family: Bookman;
}

a, a:hover {
    color: #C70039 ;
}

</style>

# {.tabset .tabset-fade .tabset-pills}

## 1. **Synopsis**

The Data was collected from [**Kaggle**](https://www.kaggle.com/). In this project we present to you exploratory data analysis, visualizations and modelling of New York Airbnb data. Airbnb, Inc.is an online marketplace for arranging or offering lodging, primarily homestays, or tourism experiences. The company does not own any of the real estate listings, nor does it host events; it acts as a broker, receiving commissions from each booking. Revenue for Airbnb comes from its guests and hosts: hosts are charged 3% of the value of the booking, while guests are charged 6%-12% per the nature of the booking. Airbnb market is quite blooming in New York city (NYC) which had more than 48,000 listings as of August-2019 calendar year.

We focus on New York City’s data as we wish to perform an in-depth analysis on one of the most densely populated cities in the world. 

In this project, we also try to predict the factors that affect the pricing of the airbnbs around New York. This includes creating different kind of models, model specification, transformation, variable selection and many more.

We carried out the project in the following steps:
  
  * Data Cleaning and Preparation
  * Data Visualization
  * Modelling and Model Checking
  * Finalising the Model
  * Prediction using the Final Model.
  
The original Data Set can be found here ---> [**New York AirBnB Data 2019**](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data)


![](Images/Airbnb Logo.jpg)


***


## 2. **Packages Required**
We begin by loading the packages that will be required throughout the course of our analysis.

```{r Loading the required packages, results='hide', echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

#install DAAG from archived source
if(!is.element("DAAG", installed.packages()[,1])){
  packageurl <- "https://cran.r-project.org/src/contrib/Archive/DAAG/DAAG_1.22.tar.gz"
  install.packages("latticeExtra")
  install.packages(packageurl, repos=NULL, type="source")
}


library(tidyr)
library(DT)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(kableExtra)
library(lubridate)
library(readxl)
library(highcharter)
library(lubridate)
library(scales)
library(RColorBrewer)
library(wesanderson)
library(plotly)
library(shiny)
library(readxl)
library(readr)
library(choroplethr)
library(choroplethrMaps)
library(GGally)
library(zoo)
library(scales)
library(ggmap)
library(stringr)
library(gridExtra)
library(caret)
library(treemap)
library(psych)
library(DAAG)
library(leaps)
library(corrplot)
library(glmnet)
library(boot)
```
***

The packages used can be found in a tabular format below. The table also describes the usage of each packages that we are using.

```{r displaying the packages table, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
#Reading the variable summary excel File
package_summary <- read_excel("Package_Summary.xlsx")

kable(package_summary) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, fixed_thead = T, )
``` 

****

## 3. **Data Preparation** {.tabset .tabset-fade .tabset-pills}


After loading the required packages, we move on to the data perparation step which would start by loading the data into our R-studio.

### 3.1 Loading and Reading the Data 

```{r Loading the data, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE, fig.align='center'}

airbnb_data <- data.table::fread("new_york_city_airbnb_open_data/AB_NYC_2019.csv")
str(airbnb_data)

```

<!-- #### Converting the character variables to Factor Variables -->

```{r Converting character variables to Factor, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE, fig.align='center' }
airbnb_data <- data.frame(airbnb_data)

airbnb_data <- mutate_if(airbnb_data, is.character, as.factor)
```

<h2> Summary and Glimpse of the Data </h2>
```{r Summary and Glimpse of the Data, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

summary(airbnb_data)

glimpse(airbnb_data)

```


<h3> Observations </h3>

1. The dataset was imported into R studio and it was found to have 48895 observations and 16 variables.
2. Data type of all categorical variables was 'Character', thus it was changed to categorical.
3. Summary statistics reveal 'Entire home or apartment' is the most common type of Airbnb followed by a 'private room'. 'Shared rooms' are the least common. Amongst Neighbourhood groups, Manhattan has the highest number of Air BnB’s followed by Brooklyn. Staten Island has the least number. It also shows that minimum price is 0, mean price is 152.7 and maximum price is 10,000 which is quite unusal, indicating potential ouliers.

<h2> Checking for NA </h2>

Next we will check for missing values and deal with them accordingly. 
```{r Checking for NA, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

summary(is.na(airbnb_data))

```


We visualise the number of missings in each variable using naniar `gg_miss_var`
```{r Visualizing the Missing Values, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center' }

naniar::gg_miss_var(airbnb_data) +
  theme_minimal()+
  labs(y = "Look at all the Missing Values") 

```

<h3> Observations </h3>

Analysis for missing values shows that there are no missing values in our dataset except for the variable ‘review per month’ which has 10052 missing values. Since we are planning to keep this variable in our study, we will decide later how we are going to deal with these missing values.

****

### 3.2 Data Cleaning

The Original Dataset [**New York AirBnB Data 2019**](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data) we collected from Kaggle did not need much cleaning. The Data set is almost clean with only one coloumn - ```reviews_per_month``` having 10052 N/A values. Deleting all these observatio now would not be a good solution as it is a high number and would result in biased results. Apart from that, all the variables were properly named and was already in proper case, hence variable need not be renamed. All the character variables were changed to factor variables.

****

### 3.3 Cleaned Dataset

The final cleaned dataset can be found below in an interactive table.


```{r Datatable, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center' }

datatable(head(airbnb_data, 20), class = 'cell-border stripe')

```

****

### 3.4 Summary of Variables

```{r displaying the summary variables table, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center'}

#Reading the variable summary excel File
var_sum <- read_excel("variable_summary.xlsx")

kable(var_sum) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, fixed_thead = T, )
```

****

## 4. **Exploratory Data Analysis** 



<h2> Which Type of Listings are there in the Neighbourhood? </h2>

We do an analysis to find out the type of listings that are common to a particular neighbourhood.

```{r Neighbourhood Property, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}
property_df <-  airbnb_data %>% 
  group_by(neighbourhood_group, room_type) %>% 
  summarize(Freq = n())

# propertydf <- propertydf %>% 
#   filter(property_type %in% c("Apartment","House","Condominium","Townhouse", "Loft"))

total_property <-  airbnb_data %>% 
  filter(room_type %in% c("Private room","Entire home/apt","Entire home/apt")) %>% 
  group_by(neighbourhood_group) %>% 
  summarize(sum = n())

property_ratio <- merge (property_df, total_property, by="neighbourhood_group")

property_ratio <- property_ratio %>% 
  mutate(ratio = Freq/sum)

ggplot(property_ratio, aes(x=neighbourhood_group, y = ratio, fill = room_type)) +
  geom_bar(position = "dodge", stat="identity") + 
  xlab("Borough") + ylab ("Count") +
  scale_fill_discrete(name = "Property Type") + 
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Which types of Listings are there in NYC?",
          subtitle = "Map showing Count of Listing Type by Borough ") +
          theme(plot.title = element_text(face = "bold", size = 14) ) +
          theme(plot.subtitle = element_text(face = "bold", color = "grey35", hjust = 0.5)) +
          theme(plot.caption = element_text(color = "grey68"))+scale_color_gradient(low="#d3cbcb", high="#852eaa")+
          scale_fill_manual("Property Type", values=c("#e06f69","#357b8a", "#7db5b8", "#59c6f3", "#f6c458")) +
          xlab("Neighborhood") + ylab("Percentage")
```

<h3> Observations </h3>

1. Private room is the most common listing type in all neigbourhoods except Manhattan where Entire Home/apartment is the most common type.
2. Shared room is the least common in all neigbourhoods.


<h2> Mean Price Comparison for each Neighbourhood Group </h2>

We want to see the average prices of listing in every neighbourhood.


```{r Price vs Neighbourhood Group, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='markup'}
airbnb_data %>% 
  filter(!(is.na(neighbourhood_group))) %>% 
  filter(!(neighbourhood_group == "Unknown")) %>% 
  group_by(neighbourhood_group) %>% 
  summarise(mean_price = mean(price, na.rm = TRUE)) %>% 
  ggplot(aes(x = reorder(neighbourhood_group, mean_price), y = mean_price, fill = neighbourhood_group)) +
  geom_col(stat ="identity", color = "black", fill="#357b8a") +
  coord_flip() +
  theme_gray() +
  labs(x = "Neighbourhood Group", y = "Price") +
  geom_text(aes(label = round(mean_price,digit = 2)), hjust = 2.0, color = "white", size = 3.5) +
  ggtitle("Mean Price comparison for each Neighbourhood Group", subtitle = "Price vs Neighbourhood Group") + 
  xlab("Neighbourhood Group") + 
  ylab("Mean Price") +
  theme(legend.position = "none",
        plot.title = element_text(color = "black", size = 14, face = "bold", hjust = 0.5),
        plot.subtitle = element_text(color = "darkblue", hjust = 0.5),
        axis.title.y = element_text(),
        axis.title.x = element_text(),
        axis.ticks = element_blank())
```
<h3> Observations </h3>

1. Average price of listings is the highest for Manhattan (196.88 USD) followed by Brookyln (124.28). One possible reason for high average price in Manhattan could be that whole apartments/home are the most common type of listings there.
2. Bronx has the cheapest listings with an average price of 87.5 USD.

<h2> Mean Price Comparison for each Room Type </h2>

```{r Price vs Room Type, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='markup'}
airbnb_data %>% 
  filter(!(is.na(room_type))) %>% 
  filter(!(room_type == "Unknown")) %>% 
  group_by(room_type) %>% 
  summarise(mean_price = mean(price, na.rm = TRUE)) %>% 
  ggplot(aes(x = reorder(room_type, mean_price), y = mean_price, fill = room_type)) +
  geom_col(stat ="identity", color = "black", fill="#357b8a") +
  coord_flip() +
  theme_gray() +
  labs(x = "Room Type", y = "Price") +
  geom_text(aes(label = round(mean_price,digit = 2)), hjust = 2.0, color = "white", size = 3.5) +
  ggtitle("Mean Price comparison with all Room Types", subtitle = "Price vs Room Type") + 
  xlab("Room Type") + 
  ylab("Mean Price") +
  theme(legend.position = "none",
        plot.title = element_text(color = "black", size = 14, face = "bold", hjust = 0.5),
        plot.subtitle = element_text(color = "darkblue", hjust = 0.5),
        axis.title.y = element_text(),
        axis.title.x = element_text(),
        axis.ticks = element_blank())
```

<h3> Observations </h3>

1. Average price is the highest for Entire home.apartment followed by private room and shared room which is quite expected.

## 5. **Modelling** {.tabset .tabset-fade .tabset-pills}


### 5.1 Data Splitting


Prior to modelling, we will split the data into Training set and Testing set so that we can use the testing set to validate our model. As it is a good practice, we are splitting the dataset in to parts in the ratio of 70:30. Training set will be 70% percent of the original data. We will use the test dataset in the future for testing and prediction purposes. Objects with price equal to 0 will be ommited since price can’t be 0 (faulty records). In order to remove the outliers, we are filtering the airbnb data by removing the extreme values of price from both sides (10% from both the end).They would make predictive models significantly weaker. 


```{r remove the outliers in Price, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center',}

airbnb_filtered_data <- airbnb_data %>% 
  filter(price < quantile(airbnb_data$price, 0.9) & price > quantile(airbnb_data$price, 0.1)) %>% 
  drop_na()

```



```{r Splitting the Data for Training and Testing, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

set.seed(123456)

airbnb_filtered_data <- airbnb_filtered_data %>% mutate(id = row_number())

airbnb_train <- airbnb_filtered_data %>% sample_frac(.7) %>% filter(price > 0)

airbnb_test  <- anti_join(airbnb_filtered_data, airbnb_train, by = 'id') %>% filter(price > 0)

```


```{r Sanity Check, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center' }

# sanity check
nrow(airbnb_train) + nrow(airbnb_test) == nrow(airbnb_filtered_data %>% filter(price > 0))

```


<h3> Observations </h3>

1. The resulting training dataset has 34,221 observations and testing dataset has 14.663 observations.
2. Sanity check confirms that that after removing the observations with price 0 and splitting the dataset, the sum of observations in test and train dataset is equal to the total number of observations in the original dataset.

In our model, we won't be considering the below variables and the reasons for the same are provided in the summary below. 

***Summary of Variables Excluded:***

* id: Unique Identifier, so not relevant to the study
* name: Identifier, so not relevant to the study
* host_id: Unique Identifier, so not relevant to the study
* host_name: Identifier, so not relevant to the study
* neighbourhood: Redundant variable as we are already taking neighbourhood_group in our study
* last_review: categorical variable with a high number of categories, will unnecessarity complicate our model

Hence, we try to predict the **price** of the airbnbs using the remaining covariates:

* neighbourhood_group
* latitude  
* longitude  
* room_type 
* minimum_nights  
* number_of_reviews 
* reviews_per_month 
* calculated_host_listings_count 
* availability_365


****


### 5.2 Model Building Process {.tabset .tabset-fade .tabset-pills}

#### 5.2.1 1st Linear Regression Model


We will build our initial linear model using all the variables that we have selected for the study.
```{r 1st Linear Regression Model, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='hide'}
airbnb_model_1 <- lm (price ~ neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + reviews_per_month + calculated_host_listings_count +
                        availability_365, data = airbnb_train)

summary_model_1 <- summary(airbnb_model_1)
mse_1 <- summary_model_1$sigma^2
r_sq_1 <- summary_model_1$r.squared
adj_r_sq_1 <- summary_model_1$adj.r.squared

summary_model_1

```
```{r Model 1 Observations, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }

cat("Model 1 Observations: \n")
cat("MSE:" , mse_1 , "\n")
cat("R-squared:", r_sq_1, "\n")
cat("Adjusted R-squared:", adj_r_sq_1, "\n")

```


<h2>Model 1 Observations: </h2>

* MSE: 1651  
* R-squared: 0.446
* Adjusted R-squared: 0.446

<h2> **Plot of the 1st Linear Regression Model** </h2>
```{r Linear Regression Model 1, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

par(mfrow=c(2,2)) 
plot(airbnb_model_1)

```
<h3> Observations </h3>

1. Residuals vs fitted values shows that the dots are not evenly distributed around zero and do not show a constant variance around X. This means that linearity and equal variance assumptions are not satisifed.
2. QQ plot shows a 45 degree line meaning that Nomrality assumptions are met. 



****


#### 5.2.2 **Variable Selection Method** {.tabset .tabset-fade .tabset-pills}

We will use both Subset regression method as well as step-wise regression for variable selection and see how the models differ in from each other.

##### **Best Subset Regression Method**
```{r Model Selection Method 1, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='hide'}

best_fit_model <- regsubsets (price ~ neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + 
                                 reviews_per_month +calculated_host_listings_count + availability_365, data = airbnb_train,  nbest = 2, nvmax = 9)

summary(best_fit_model)

```


```{r Plot BFM, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', }
plot(best_fit_model, scale="bic")
```

<h3> Observations </h3>

1. Using Section method with BIC, we find that the top 4 models have the same and lowest BIC. We will pick our covariates based on the model which has the highest adjusted R-squared and lowest MSPE.
2. On doing the analysis in our test script, we find that the top most model is one with lowest MSPE and highest adjusted R-Squared.
3. Based on the results, the covariates that we have to select here are:

* neighbourhood_group
* latitude
* longitude
* minimum_nights
* room_type
* availablity_365
* calculated_host_listings_count

Next we will create a model using the the above mentioned covariates


```{r Best Subset Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }

airbnb_model_3 <- lm (price ~ room_type + neighbourhood_group  + latitude + longitude  + minimum_nights +
                        availability_365 + calculated_host_listings_count , data = airbnb_train, nbest = 2, nvmax = 9)



summary_model_3 <- summary(airbnb_model_3)
mse_3 <- summary_model_3$sigma^2
r_sq_3 <- summary_model_3$r.squared
adj_r_sq_3 <- summary_model_3$adj.r.squared

summary_model_3

```

```{r Display Model 3 Summary, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }
cat("Model 3 Observations: \n")
cat("MSE:" , mse_3 , "\n")
cat("R-squared:", r_sq_3, "\n")
cat("Adjusted R-squared:", adj_r_sq_3, "\n")
```

<h2> Model 3 Observations: </h2>

* MSE: 1653 
* R-squared: 0.445
* Adjusted R-squared: 0.445

****


##### **Stepwise Regression with AIC/BIC** {.tabset .tabset-fade .tabset-pills}

###### **Stepwise selection using AIC** (Direction = "both")
```{r stepwise selection using AIC, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center',}

null <- lm(price~1, data = airbnb_train)
full <- lm(price ~ neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + 
                                 reviews_per_month +calculated_host_listings_count + availability_365, data = airbnb_train)

step(null, scope =list(lower=null, upper= full), direction = "both")

```

The covariates given by this fit are as follows:

* room_type
* neighbourhood_group
* longitude 
* availability_365
* calculated_host_listings_count
* minimum_nights
* latitude
* number_of_reviews

Hence, Building a Model using this co variates:
```{r AIC Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }

airbnb_model_4 <- lm(price ~ room_type + neighbourhood_group + longitude + availability_365 + calculated_host_listings_count + minimum_nights + latitude + number_of_reviews, 
                     data = airbnb_train, nbest = 2, nvmax = 9)


summary_model_4 <- summary(airbnb_model_4)
mse_4 <- summary_model_4$sigma^2
r_sq_4 <- summary_model_4$r.squared
adj_r_sq_4 <- summary_model_4$adj.r.squared

summary_model_4

```

```{r Display Model 4 Summary, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }
cat("Model 4 Observations: \n")
cat("MSE:" , mse_4 , "\n")
cat("R-squared:", r_sq_4, "\n")
cat("Adjusted R-squared:", adj_r_sq_4, "\n")
```
 <h2> Model 4 Observations: </h2>
 
* MSE: 1651
* R-squared: 0.446
* Adjusted R-squared: 0.446

###### **stepwise selection using BIC** (Direction = "both")



```{r stepwise selection using BIC, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center',  }

null <- lm(price~1, data = airbnb_train)
full <- lm(price ~ neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + 
                                 reviews_per_month +calculated_host_listings_count + availability_365, data = airbnb_train)

n=dim(airbnb_train[1])
step(null, scope =list(lower=null, upper= full), k=log(n), direction = "both")

```

The covariates given by this fit are as follows:

* room_type
* neighbourhood_group
* longitude
* availability_365
* minimum_nights
* calculated_host_listings_count
* latitude
* number_of_reviews
* reviews_per_month

Hence, Building a Model using this co variates:
```{r BIC Model 5, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }

airbnb_model_5 <- lm(price ~ room_type + neighbourhood_group + longitude + availability_365 + minimum_nights + latitude + calculated_host_listings_count + 
                       number_of_reviews + reviews_per_month, data = airbnb_train, nbest = 2, nvmax = 9)


summary_model_5 <- summary(airbnb_model_5)
mse_5 <- summary_model_5$sigma^2
r_sq_5 <- summary_model_5$r.squared
adj_r_sq_5 <- summary_model_5$adj.r.squared

summary_model_5

```


```{r Display Model 5 Summary, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }
cat("Model 5 Observations: \n")
cat("MSE:" , mse_5 , "\n")
cat("R-squared:", r_sq_5, "\n")
cat("Adjusted R-squared:", adj_r_sq_5, "\n")
```

<h2> Model 5 Observations: </h2>
* MSE:  1651
* R-squared: 0.446 
* Adjusted R-squared: 0.446 

***




##### **Lasso Regression Method**

Next we use the Lasso Regression method for variable selection.

```{r Lasso Regression Method, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup' }

lasso_fit <- glmnet(x = as.matrix(airbnb_train[, -c(which(colnames(airbnb_train) %in% c("room_type", "neighbourhood_group","price", "name", "host_name", 
                                                                                        "neighbourhood", "last_review", "host_id", "id")))]), 
                    y = airbnb_train$price, alpha = 0.5)

coef(lasso_fit,s = lasso_fit$lambda.min)


```

The covariates given out by this fit are:

* latitude                        
* longitude                      
* minimum_nights                 
* number_of_reviews              
* reviews_per_month              
* calculated_host_listings_count  
* availability_365           

Hence, we will build a Model using these covariates
```{r Lasso Fit Model 6,  echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup' }

airbnb_model_6 <- lm(price ~ latitude + longitude + minimum_nights + number_of_reviews + reviews_per_month + calculated_host_listings_count + availability_365,
                     data = airbnb_train, nbest = 2, nvmax = 9)


summary_model_6 <- summary(airbnb_model_6)
#mse_6 <- mean(summary_model_6$sigma^2)
mse_6 <- mean(summary_model_6$residuals^2)
r_sq_6 <- summary_model_6$r.squared
adj_r_sq_6 <- summary_model_6$adj.r.squared

summary_model_6

```

```{r Display Model 6 Summary, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide'}
cat("Model 6 Observations: \n")
cat("MSE:" , mse_6 , "\n")
cat("R-squared:", r_sq_6, "\n")
cat("Adjusted R-squared:", adj_r_sq_6, "\n")
```

<h2> Model 6 Observations: </h2>

* MSE: 2687 
* R-squared: 0.0981 
* Adjusted R-squared: 0.0978 

Cross Validation of Lasso Fit:
```{r Cross Validation of Lasso Fit, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}
cv_lasso_fit = cv.glmnet(x = as.matrix(airbnb_train[, -c(which(colnames(airbnb_train) %in% c("room_type", "neighbourhood_group","price" , "name", "host_name",
                                                                                                          "neighbourhood", "last_review")))]), 
                    y = airbnb_train$price, alpha = 1, nfolds = 5)
plot(cv_lasso_fit)
```


### 5.3. Model Selection

In order to pick a model from the ones that we have built, we will do a comparison MSPE and adjusted R-squared of all the models and choose the model with the best combination of both.


<h2> Comparison of all the Models: </h2>

```{r Comparison of Models, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}



#Reading the variable summary excel File
model_sum <- read_excel("Model_Comparison.xlsx")

kable(model_sum) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, fixed_thead = T, )
```

<h3> Observations </h3>

1. The model built using Lasso Regression is the least desirable one as it has the lowest adjusted R-squared and highest MSE value.
2. The linear model built using stepwise regression using both AIC and BIC have the best combination of MSE and Adjusted R-squared and these values are same for both of them. However, we are selecting the ``` **Model 5** (stepwise regression using BIC)``` as BIC is considered to be more **Conservative** and it gives the Lesser number of Variables when compared to AIC, thus making the model more interpretable.

<h2> Summary of Model 5 </h2>
```{r BIC Model 5 Selected, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', }


summary_model_5 <- summary(airbnb_model_5)
mse_5 <- summary_model_5$sigma^2
r_sq_5 <- summary_model_5$r.squared
adj_r_sq_5 <- summary_model_5$adj.r.squared

summary_model_5

```


### 5.4 Validation and Prediction

<h2>In-sample model evaluation (train error)</h2>

<h3> MSE of the Final Selected Model </h3>
```{r MSE of Final Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}

(summary_model_5$sigma)^2

```


<h3> R2 of the Final Selected Model </h3>
```{r r2 of Final Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}

summary_model_5$r.squared

```

<h3> Adjusted R2 of the Final Selected Model </h3>
```{r adj r2 of Final Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}

  summary_model_5$adj.r.squared

```


<h2> Out-of-sample prediction (test error) </h2>

To evaluate how the model performs on future data, we use predict() to get the predicted values from the test set.

```{r prediction on test dataset, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}
#pi is a vector that contains predicted values for test set.
pi <- predict(object = airbnb_model_5, newdata = airbnb_test)
```


<h3>Mean Squared Error (MSE) of the final Model: </h3>

```{r MSE of test dataset, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}
mean((pi - airbnb_test$price)^2)

```


<h3>the Mean Absolute Error (MAE) of the Final Model - Test Data. </h3>

```{r MAE of test dataset, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}

mean(abs(pi - airbnb_test$price))


```

<h2> Cross Validation of the Final Selected Model </h2>

<h3> MSPE of the Full Filtered Data </h3>

```{r MSPE of Full Data, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}
model_glm_1 = glm(price~neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + 
                                 reviews_per_month +calculated_host_listings_count + availability_365,  data = airbnb_filtered_data)

cv.glm(data =airbnb_filtered_data, glmfit = model_glm_1, K = 3)$delta[2]
```

Comparing the MSE of Test Dataset which is equal to 1633, and the MSPE of the Full Data which is 1646, we can see that the values are almost similar. Hence the variables that we have selected for our model are good estimators of our dependent variable.


## 6. **Conclusion**

<h3> Summary of the problem: </h3>

To Analyze the New York Air Bnb dataset and find the interesting insights related to the factors that affect the prices of listing in New York city. We tried to answer the following questions using our analysis:


	
* How are rental properties distributed across the neighborhoods of NYC?
* How do prices vary with respect to other factors?


Date Used and Methodology: The data is collected from an online data-source [**Kaggle**](https://www.kaggle.com/).


<h3> Methodology: </h3>

We used multiple regression method to create a model that would help predict prices of listing based on relevant factors. We started with importing and cleaning the data followed by exploratory analysis to gain some interesting insights.  For model building, we decided to split the dataset into training and testing datasets in the ratio of 70:30. We created an initial model using all the variables we thought were relevant, followed by building models using 4 different variable selections methods i.e. stepwise-regression methods (using AIC and BIC both), regression subset method and Lasso regression methods. MSE, R^2, Adj R^2  of these 5 models were then compared in order to pick the best model. Next, we performed in-sample validation, out-sample prediction and cross-validation techniques on the final selected model. Upon validation, we found that the MSPE of Test Dataset i.e. 1633 is almost similar to the MSPE of the Full Data i.e. 1646. Hence, we could conclude that the Model selected for analysis, predicts the variable with a good fit. 

Interesting insights from Analysis The above analysis helped us understand the New York Air Bnb dataset better. Following insights were drawn from it:


	
* Private room is the most common listing type in all neighborhoods except Manhattan where Entire Home/apartment is the most common type.
* Shared room is the least common type of listings.
*	Average price of listings is the highest for Manhattan followed by Brooklyn. 
*	Bronx has the cheapest listings with an average price of 87.5 USD.
*	Average price is the highest for Entire home/apartment followed by private room and shared room.
*	The factors that impact listing prices are:
	  * room_type
		* neighbourhood_group
		* longitude
		* availability_365
		* minimum_nights
		* calculated_host_listings_count
		* latitude
		* number_of_reviews
		* reviews_per_month
	

<h3> Implications from the analysis: </h3>

This information can be really helpful for multiple categories of the society such as tourists, house owners, real estate agents etc. It can help customers decide which neighborhoods they should look into depending on their needs and house owners can decide on the prices they set on the listings taking all these factors into consideration.

<h3> Final Model </h3>

The Final Model selected was ```Model 5```. This Model was selected by ```Stepwise Regression using BIC (direction : both)```. The Observations of the Model:


* MSE:  1651
* R-squared: 0.446 
* Adjusted R-squared: 0.446 

<h3> The Covariates in the Model </h3>

* room_type
* neighbourhood_group
* longitude
* availability_365
* minimum_nights
* calculated_host_listings_count
* latitude
* number_of_reviews
* reviews_per_month