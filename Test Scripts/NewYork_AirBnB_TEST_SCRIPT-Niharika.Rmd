---
title: "<center><b> New York AirBnB <br> Exploratory Data Analysis and Modelling </b></center>"
subtitle: "<center><b> Price Prediction for AirBnbs in New York </b></center>"
author: <center> Sayak Chakraborty | Samreen Zehra | Niharika Gupta | Rohit Thakur
  </center>
output:
  html_document:
    code_folding: show
  word_document: default
always_allow_html: yes
---

<style>
body {
        text-align: justify
     }
</style>

# {.tabset .tabset-fade .tabset-pills}

## 1. **Synopsis**

The Data was collected from [**Kaggle**](https://www.kaggle.com/). In this project we present to you exploratory data analysis, visualizations of New York Airbnb data. We focus on New York City’s data as we wish to perform an in-depth analysis on one of the most densely populated cities in the world. 

In this project, we also try to predict the factors that affect the pricing of the airbnbs around New York. This includes creating different kind of models, model specification, transformation, variable selection and many more.

We carried out the project in the following steps:
  
  * Data Cleaning and Preparation
  * Data Visualization
  * Modelling and Model Checking
  * Finalising the Model
  * Prediction using the Final Model.
  
The original Data Set can be found here ---> [**New York AirBnB Data 2019**](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data)


![](Images/Airbnb Logo.jpg)


***


## 2. **Packages Required**

```{r Loading the required packages, results='hide', echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

#install DAAG from archived source
if(!is.element("DAAG", installed.packages()[,1])){
  packageurl <- "https://cran.r-project.org/src/contrib/Archive/DAAG/DAAG_1.22.tar.gz"
  install.packages("latticeExtra")
  install.packages(packageurl, repos=NULL, type="source")
}


library(tidyr)
library(DT)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(kableExtra)
library(lubridate)
library(readxl)
library(highcharter)
library(lubridate)
library(scales)
library(RColorBrewer)
library(wesanderson)
library(plotly)
library(shiny)
library(readxl)
library(readr)
library(choroplethr)
library(choroplethrMaps)
library(GGally)
library(zoo)
library(scales)
library(ggmap)
library(stringr)
library(gridExtra)
library(caret)
library(treemap)
library(psych)
library(DAAG)
library(leaps)
library(corrplot)
library(glmnet)
library(boot)
```
***

The packages that we will be utilizing to carry out our study can be found in a tabular format below. The table  describes the usage of each packages that we are using.

```{r displaying the packages table, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
#Reading the variable summary excel File
package_summary <- read_excel("Package_Summary.xlsx")

kable(package_summary) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, fixed_thead = T, )
``` 

****

## 3. **Data Preparation** {.tabset .tabset-fade .tabset-pills}


After loading the required packages, we move on to the data perparation step which would start by loading the data into our R-studio.

### 3.1 Loading and Reading the Data 

```{r Loading the data, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE, fig.align='center'}

airbnb_data <- data.table::fread("new_york_city_airbnb_open_data/AB_NYC_2019.csv")

```

<!-- #### Converting the character variables to Factor Variables -->

```{r Converting character variables to Factor, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE, fig.align='center' }
airbnb_data <- data.frame(airbnb_data)

airbnb_data <- mutate_if(airbnb_data, is.character, as.factor)
```

<h2> Summary and Glimpse of the Data </h2>
```{r Summary and Glimpse of the Data, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

summary(airbnb_data)

glimpse(airbnb_data)

```


<h3> Observations </h3>

1. The dataset was imported into R studio and it was found to have 48895 observations and 16 variables.
2. Data type of all categorical variables was 'Character', thus it was changed to categorical.
3. Summary statistics reveal 'Entire home or apartment' is the most common type of Airbnb followed by a 'private room'. 'Shared rooms' are the least common. Amongst Neighborhood groups, Manhattan has the highest number of Air BnB’s followed by Brooklyn. Staten Island has the least number. It also shows that minimum price is 0, mean price is 152.7 and maximum price is 10,000 which is quite unusal, indicating potential ouliers.

<h2> Checking for NA </h2>

Next we will check for missing values and deal with them accordingly. 
```{r Checking for NA, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

summary(is.na(airbnb_data))

```



We visualise the number of missings in each variable using naniar `gg_miss_var`
```{r Visualizing the Missing Values, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center' }

naniar::gg_miss_var(airbnb_data) +
  theme_minimal()+
  labs(y = "Look at all the Missing Values") 

```

<h3> Observations </h3>

Analysis for missing values shows that there are no missing values in our dataset except for the variable ‘review per month’ which has 10052 missing values. Since we are planning to keep this variable in our study, we will decide later how we are going to deal with these missing values.

****

### 3.2 Data Cleaning

****

### 3.3 Cleaned Dataset

The final cleaned dataset can be found below in an interactive table.


```{r Datatable, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center' }

datatable(head(airbnb_data, 20), class = 'cell-border stripe')

```

****

### 3.4 Summary of Variables

```{r displaying the summary variables table, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center'}

#Reading the variable summary excel File
var_sum <- read_excel("variable_summary.xlsx")

kable(var_sum) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, fixed_thead = T, )
```

****

## 4. **Exploratory Data Analysis** 



<h2> Which Type of Listings are there in the Neighbourhood? </h2>

We do a  data analysis to find out the type of listings that are common to a particular neighbourhood.

```{r Neighbourhood Property, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
property_df <-  airbnb_data %>% 
  group_by(neighbourhood_group, room_type) %>% 
  summarize(Freq = n())

# propertydf <- propertydf %>% 
#   filter(property_type %in% c("Apartment","House","Condominium","Townhouse", "Loft"))

total_property <-  airbnb_data %>% 
  filter(room_type %in% c("Private room","Entire home/apt","Entire home/apt")) %>% 
  group_by(neighbourhood_group) %>% 
  summarize(sum = n())

property_ratio <- merge (property_df, total_property, by="neighbourhood_group")

property_ratio <- property_ratio %>% 
  mutate(ratio = Freq/sum)

ggplot(property_ratio, aes(x=neighbourhood_group, y = ratio, fill = room_type)) +
  geom_bar(position = "dodge", stat="identity") + 
  xlab("Borough") + ylab ("Count") +
  scale_fill_discrete(name = "Property Type") + 
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Which types of Listings are there in NYC?",
          subtitle = "Map showing Count of Listing Type by Borough ") +
          theme(plot.title = element_text(face = "bold", size = 14) ) +
          theme(plot.subtitle = element_text(face = "bold", color = "grey35", hjust = 0.5)) +
          theme(plot.caption = element_text(color = "grey68"))+scale_color_gradient(low="#d3cbcb", high="#852eaa")+
          scale_fill_manual("Property Type", values=c("#e06f69","#357b8a", "#7db5b8", "#59c6f3", "#f6c458")) +
          xlab("Neighborhood") + ylab("Percentage")
```

<h3> Observations </h3>

1. Private room is the most common listing type in all neigborhoods except Manhattan where Entire Home/aoartment is the most common type.
2. Shared room is the least common in all neigborhoods.


<h2> Mean Price Comparison for each Neighbourhood Group </h2>

We want to see the average prices of listing in every neighbourhood.


```{r Price vs Neighbourhood Group, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='markup'}
airbnb_data %>% 
  filter(!(is.na(neighbourhood_group))) %>% 
  filter(!(neighbourhood_group == "Unknown")) %>% 
  group_by(neighbourhood_group) %>% 
  summarise(mean_price = mean(price, na.rm = TRUE)) %>% 
  ggplot(aes(x = reorder(neighbourhood_group, mean_price), y = mean_price, fill = neighbourhood_group)) +
  geom_col(stat ="identity", color = "black", fill="#357b8a") +
  coord_flip() +
  theme_gray() +
  labs(x = "Neighbourhood Group", y = "Price") +
  geom_text(aes(label = round(mean_price,digit = 2)), hjust = 2.0, color = "white", size = 3.5) +
  ggtitle("Mean Price comparison for each Neighbourhood Group", subtitle = "Price vs Neighbourhood Group") + 
  xlab("Neighbourhood Group") + 
  ylab("Mean Price") +
  theme(legend.position = "none",
        plot.title = element_text(color = "black", size = 14, face = "bold", hjust = 0.5),
        plot.subtitle = element_text(color = "darkblue", hjust = 0.5),
        axis.title.y = element_text(),
        axis.title.x = element_text(),
        axis.ticks = element_blank())
```
<h3> Observations </h3>

1. Average price of listings is the highest for Manhattan (196.88 USD) followed by Brookyln (124.28). One possible reason for high average price in Manhattan could also be that whole apartments/home are the most common type of listings there.
2. Bronx has the cheapest listings with an average price od 87.5 USD.

<h2> Mean Price Comparison for each Room Type </h2>

```{r Price vs Room Type, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='markup'}
airbnb_data %>% 
  filter(!(is.na(room_type))) %>% 
  filter(!(room_type == "Unknown")) %>% 
  group_by(room_type) %>% 
  summarise(mean_price = mean(price, na.rm = TRUE)) %>% 
  ggplot(aes(x = reorder(room_type, mean_price), y = mean_price, fill = room_type)) +
  geom_col(stat ="identity", color = "black", fill="#357b8a") +
  coord_flip() +
  theme_gray() +
  labs(x = "Room Type", y = "Price") +
  geom_text(aes(label = round(mean_price,digit = 2)), hjust = 2.0, color = "white", size = 3.5) +
  ggtitle("Mean Price comparison with all Room Types", subtitle = "Price vs Room Type") + 
  xlab("Room Type") + 
  ylab("Mean Price") +
  theme(legend.position = "none",
        plot.title = element_text(color = "black", size = 14, face = "bold", hjust = 0.5),
        plot.subtitle = element_text(color = "darkblue", hjust = 0.5),
        axis.title.y = element_text(),
        axis.title.x = element_text(),
        axis.ticks = element_blank())
```

<h3> Observations </h3>

1. Average price is the highest for Entire home.apartment followed by private room and shared room which is pretty obvious.

## 5. **Modelling** {.tabset .tabset-fade .tabset-pills}


### 5.1 Data Splitting


Prior to modelling, we will split the data into Training set and Testing set so that we can used the testing set to validate our model. As, it is a good practice, we are splitting the dataset in to parts in the ratio of 70:30. Training set will be 70% percent of the original data. We will use the test dataset in the future for testing and prediction purposes. Objects with price equal to 0 will be ommited since price can’t be 0 (faulty records). In order to remove the outliers, we are filtering the airbnb data by removing the extreme values of price from both sides (10% from both the end).They would make predictive models significantly weaker. 


```{r remove the outliers in Price, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center',}

airbnb_filtered_data <- airbnb_data %>% 
  filter(price < quantile(airbnb_data$price, 0.9) & price > quantile(airbnb_data$price, 0.1)) %>% 
  drop_na()

```


As, it is a good practice, we are splitting the dataset in to parts in the ratio of 70:30. Training set will be 70% percent of the original data. Objects with price equal to 0 will be ommited since price can’t be 0 (faulty records). They would make predictive models significantly weaker. We will use the test dataset in the future for testing and prediction purposes.

```{r Splitting the Data for Training and Testing, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

set.seed(123456)

airbnb_filtered_data <- airbnb_filtered_data %>% mutate(id = row_number())

airbnb_train <- airbnb_filtered_data %>% sample_frac(.7) %>% filter(price > 0)

airbnb_test  <- anti_join(airbnb_filtered_data, airbnb_train, by = 'id') %>% filter(price > 0)

```


```{r Sanity Check, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center' }

# sanity check
nrow(airbnb_train) + nrow(airbnb_test) == nrow(airbnb_filtered_data %>% filter(price > 0))

```


<h3> Observations </h3>

1. The resulting training dataset has 34,221 observations and testing dataset has 14.663 observations.
2. Sanity check confirms that that after removing the observations with price 0 and splitting the dataset, the sum of observations in test and train dataset is equal to the total number of observations in the original dataset.

IIn our model, we won't be considering the below variables as we don't think they can have any impact the prices of listings. We have taken neighbourhood group as one of our covariates thus we are excluding neighbourhood as well. We won't be taking last reveiw as well as it is a categorical variable with a high number of categories which will unnecessarity complicate our model. Moreover, we don't think it could be of much importance to our study, 

Summary of Variables Excluded:

* id
* name
* host_id
* host_name
* neighbourhood
* last_review

Hence, we try to predict the **price** of the airbnbs using the remaining covariates:

* neighbourhood_group
* latitude  
* longitude  
* room_type 
* minimum_nights  
* number_of_reviews 
* reviews_per_month 
* calculated_host_listings_count 
* availability_365


****


### 5.2 Model Building Process {.tabset .tabset-fade .tabset-pills}

#### 5.2.1 1st Linear Regression Model

In our model, we won't be considering the below variables as we don't think they can have any impact the prices of listings. We have taken neighbourhood group as one of our covariates thus we are excluding neighbourhood as well. We won't be taking last reveiw as well as it is a categorical variable with a high number of categories which will unnecessarity complicate our model. Moreover, we don't think it could be of much importance to our study, 

Summary of Variables Excluded:

* id
* name
* host_id
* host_name
* neighbourhood
* last_review

Hence, we try to predict the **price** of the airbnbs using the remaining covariates:

* neighbourhood_group
* latitude  
* longitude  
* room_type 
* minimum_nights  
* number_of_reviews 
* reviews_per_month 
* calculated_host_listings_count 
* availability_365

We will build our initial linear model using all the variables that we have selected for the study.
```{r 1st Linear Regression Model, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='hide'}
airbnb_model_1 <- lm (price ~ neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + reviews_per_month + calculated_host_listings_count +
                        availability_365, data = airbnb_train)

summary_model_1 <- summary(airbnb_model_1)
mse_1 <- summary_model_1$sigma^2
r_sq_1 <- summary_model_1$r.squared
adj_r_sq_1 <- summary_model_1$adj.r.squared

summary_model_1

```
```{r Model 1 Observations, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }

cat("Model 1 Observations: \n")
cat("MSE:" , mse_1 , "\n")
cat("R-squared:", r_sq_1, "\n")
cat("Adjusted R-squared:", adj_r_sq_1, "\n")

```


<h2>Model 1 Observations: </h2>

* MSE: 1651  
* R-squared: 0.446
* Adjusted R-squared: 0.446

<h2> **Plot of the 1st Linear Regression Model** </h2>
```{r Linear Regression Model 1, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center'}

par(mfrow=c(2,2)) 
plot(airbnb_model_1)

```
<h3> Observations </h3>

1. Residuals vs fitted values shows that the dots are not evenly distributed around zero and do not show a constant variance around X. This means that lenearity and equal variance assumptions are not satisifed.??
2. QQ plot shows a 45 degree line meaning that Nomrality assumptions are met??


<h2>3 Fold Cross Validation of the 1st Linear Model </h2>

Next we perform a 3-fold cross-validation on the model.

```{r cross validation 1st linear model, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='hide'}

KCV_model_1=cv.lm(data=airbnb_train, airbnb_model_1, m =3 )

```


<h3> Observations </h3>
1. MSPE is 1662, Press value is 36722497, Prediction R-squared is 0.442.?

****


#### 5.2.2 **Variable Selection Method** {.tabset .tabset-fade .tabset-pills}

We will use both Subset regression method as well as step-wise regression for variable selection and see how they differ in their results.

##### **Best Subset Regression Method**
```{r Model Selection Method 1, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', results='hide'}

best_fit_model <- regsubsets (price ~ neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + 
                                 reviews_per_month +calculated_host_listings_count + availability_365, data = airbnb_train,  nbest = 2, nvmax = 9)

summary(best_fit_model)

```


```{r Plot BFM, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', }
plot(best_fit_model, scale="bic")
```

<h3> Observations </h3>

1. Using Section method with BIC, we find that the top 4 models have the same and lowest BIC. We will pick our covariates based on the model which has the 2. highest adjusted R-squared and lowest MSPE.
2. On doing the analysis in our test script, we find that the top most model is one with lowest MSPE and highest e top 4 models have the same and owest BIC. We will pick our covariates based on the model which has the highest and thus we will go with that one.
3. Based on the results, the covariates that we have to select here are:

* neighbourhood_group
* latitude
* longitude
* minimum_nights
* room_type
* availablity_365
* calculated_host_listings_count

Next we will create a model using the the above mentioned covariates


```{r Best Subset Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }

airbnb_model_3 <- lm (price ~ room_type + neighbourhood_group  + latitude + longitude  + minimum_nights +
                        availability_365 + calculated_host_listings_count , data = airbnb_train, nbest = 2, nvmax = 9)



summary_model_3 <- summary(airbnb_model_3)
mse_3 <- summary_model_3$sigma^2
r_sq_3 <- summary_model_3$r.squared
adj_r_sq_3 <- summary_model_3$adj.r.squared

summary_model_3

```

```{r Display Model 3 Summary, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }
cat("Model 3 Observations: \n")
cat("MSE:" , mse_3 , "\n")
cat("R-squared:", r_sq_3, "\n")
cat("Adjusted R-squared:", adj_r_sq_3, "\n")
```

<h2> Model 3 Observations: </h2>

* MSE: 1653 
* R-squared: 0.445
* Adjusted R-squared: 0.445

****


##### **Stepwise Regression with AIC/BIC** {.tabset .tabset-fade .tabset-pills}

###### **Stepwise selection using AIC** (Direction = "both")
```{r stepwise selection using AIC, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center',}

null <- lm(price~1, data = airbnb_train)
full <- lm(price ~ neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + 
                                 reviews_per_month +calculated_host_listings_count + availability_365, data = airbnb_train)

step(null, scope =list(lower=null, upper= full), direction = "both")

```

The covariates given by this fit are as follows:

* room_type
* neighbourhood_group
* longitude 
* availability_365
* calculated_host_listings_count
* minimum_nights
* latitude
* number_of_reviews

Hence, Building a Model using this co variates:
```{r AIC Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }

airbnb_model_4 <- lm(price ~ room_type + neighbourhood_group + longitude + availability_365 + calculated_host_listings_count + minimum_nights + latitude + number_of_reviews, 
                     data = airbnb_train, nbest = 2, nvmax = 9)


summary_model_4 <- summary(airbnb_model_4)
mse_4 <- summary_model_4$sigma^2
r_sq_4 <- summary_model_4$r.squared
adj_r_sq_4 <- summary_model_4$adj.r.squared

summary_model_4

```

```{r Display Model 4 Summary, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }
cat("Model 4 Observations: \n")
cat("MSE:" , mse_4 , "\n")
cat("R-squared:", r_sq_4, "\n")
cat("Adjusted R-squared:", adj_r_sq_4, "\n")
```
 <h2> Model 4 Observations: </h2>
 
* MSE: 1651
* R-squared: 0.446
* Adjusted R-squared: 0.446

###### **stepwise selection using BIC** (Direction = "both")



```{r stepwise selection using BIC, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center',  }

null <- lm(price~1, data = airbnb_train)
full <- lm(price ~ neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + 
                                 reviews_per_month +calculated_host_listings_count + availability_365, data = airbnb_train)

n=dim(airbnb_train[1])
step(null, scope =list(lower=null, upper= full), k=log(n), direction = "both")

```

The covariates given by this fit are as follows:

* room_type
* neighbourhood_group
* longitude
* availability_365
* minimum_nights
* calculated_host_listings_count
* latitude
* number_of_reviews
* reviews_per_month

Hence, Building a Model using this co variates:
```{r BIC Model 5, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }

airbnb_model_5 <- lm(price ~ room_type + neighbourhood_group + longitude + availability_365 + minimum_nights + latitude + calculated_host_listings_count + 
                       number_of_reviews + reviews_per_month, data = airbnb_train, nbest = 2, nvmax = 9)


summary_model_5 <- summary(airbnb_model_5)
mse_5 <- summary_model_5$sigma^2
r_sq_5 <- summary_model_5$r.squared
adj_r_sq_5 <- summary_model_5$adj.r.squared

summary_model_5

```


```{r Display Model 5 Summary, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide' }
cat("Model 5 Observations: \n")
cat("MSE:" , mse_5 , "\n")
cat("R-squared:", r_sq_5, "\n")
cat("Adjusted R-squared:", adj_r_sq_5, "\n")
```

<h2> Model 5 Observations: </h2>
* MSE:  1651
* R-squared: 0.446 
* Adjusted R-squared: 0.446 

***




##### **Lasso Regression Method**

Next we use the Lasso Regression method for variable selection.

```{r Lasso Regression Method, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup' }

lasso_fit <- glmnet(x = as.matrix(airbnb_train[, -c(which(colnames(airbnb_train) %in% c("room_type", "neighbourhood_group","price", "name", "host_name", 
                                                                                        "neighbourhood", "last_review", "host_id", "id")))]), 
                    y = airbnb_train$price, alpha = 0.5)

coef(lasso_fit,s = lasso_fit$lambda.min)


```

<h3> Observations </h3>
The covariates given out by this model are :

* latitude                        
* longitude                      
* minimum_nights                 
* number_of_reviews              
* reviews_per_month              
* calculated_host_listings_count  
* availability_365           

Hence, Building a Model using this covariates
```{r Lasso Fit Model 6,  echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup' }

airbnb_model_6 <- lm(price ~ latitude + longitude + minimum_nights + number_of_reviews + reviews_per_month + calculated_host_listings_count + availability_365,
                     data = airbnb_train, nbest = 2, nvmax = 9)


summary_model_6 <- summary(airbnb_model_6)
#mse_6 <- mean(summary_model_6$sigma^2)
mse_6 <- mean(summary_model_6$residuals^2)
r_sq_6 <- summary_model_6$r.squared
adj_r_sq_6 <- summary_model_6$adj.r.squared

summary_model_6

```

```{r Display Model 6 Summary, echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='hide'}
cat("Model 6 Observations: \n")
cat("MSE:" , mse_6 , "\n")
cat("R-squared:", r_sq_6, "\n")
cat("Adjusted R-squared:", adj_r_sq_6, "\n")
```

<h2> Model 6 Observations: </h2>

* MSE: 2687 
* R-squared: 0.0981 
* Adjusted R-squared: 0.0978 

Cross Validation of Lasso Fit:
```{r Cross Validation of Lasso Fit, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}
cv_lasso_fit = cv.glmnet(x = as.matrix(airbnb_train[, -c(which(colnames(airbnb_train) %in% c("room_type", "neighbourhood_group","price" , "name", "host_name",
                                                                                                          "neighbourhood", "last_review")))]), 
                    y = airbnb_train$price, alpha = 1, nfolds = 5)
plot(cv_lasso_fit)
```


### 5.3. Model Selection

In order to pick a model from  the ones that we have built, we will do a comparison of all the models.


<h2> Comparison of all the Models: </h2>

```{r Comparison of Models, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}



#Reading the variable summary excel File
model_sum <- read_excel("Model_Comparison.xlsx")

kable(model_sum) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, fixed_thead = T, )
```

<h3> Observations </h3>

1. The model built using Lasso Regression is the least desirable one as it has the lowest adjusted R-squared and highest MSE value.
2. The linear model built using stepwise regression using both AIC and BIC have the best combination of MSE and Adjusted R-squared and these values are same for both of them. However, we are selecting the ``` **Model 5** (stepwise regression using BIC)``` as BIC is considered to be more **Conservative** and it gives the Lesser number of Variables when compared to AIC.

<h2> Summary of Model 5 </h2>
```{r BIC Model 5 Selected, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', }


summary_model_5 <- summary(airbnb_model_5)
mse_5 <- summary_model_5$sigma^2
r_sq_5 <- summary_model_5$r.squared
adj_r_sq_5 <- summary_model_5$adj.r.squared

summary_model_5

```


### 5.4 Validation and Prediction

<h2>In-sample model evaluation (train error)</h2>

<h3> MSE of the Final Selected Model </h3>
```{r MSE of Final Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}

(summary_model_5$sigma)^2

```


<h3> R2 of the Final Selected Model </h3>
```{r r2 of Final Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}

summary_model_5$r.squared

```

<h3> Adjusted R2 of the Final Selected Model </h3>
```{r adj r2 of Final Model, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}

  summary_model_5$adj.r.squared

```


<h2> Out-of-sample prediction (test error) </h2>

To evaluate how the model performs on future data, we use predict() to get the predicted values from the test set.

```{r prediction on test dataset, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}
#pi is a vector that contains predicted values for test set.
pi <- predict(object = airbnb_model_5, newdata = airbnb_test)
```


<h3>Mean Squared Error (MSE) of the final Model: </h3>

```{r MSE of test dataset, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}
mean((pi - airbnb_test$price)^2)

```


<h3>the Mean Absolute Error (MAE) of the Final Model - Test Data. </h3>

```{r MAE of test dataset, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}

mean(abs(pi - airbnb_test$price))


```

<h2> Cross Validation of the Final Selected Model </h2>

<h3> MSPE of the Full Filtered Data </h3>

```{r MSPE of Full Data, echo=TRUE,  message=FALSE, warning=FALSE, fig.align='center', results='markup'}
model_glm_1 = glm(price~neighbourhood_group + latitude + longitude + room_type + minimum_nights  + number_of_reviews + 
                                 reviews_per_month +calculated_host_listings_count + availability_365,  data = airbnb_filtered_data)

cv.glm(data =airbnb_filtered_data, glmfit = model_glm_1, K = 3)$delta[2]
```

Comparing the MSE of Test Dataset which is equal to 1633, and the MSPE of the Full Data which is 1646, we can see that the values are almost similar. Hence The Model selected is a good Model.


## 6. **Conclusion**

<h2> Final Equation </h2>

Final Model is Model 5 Obtained by Stepwise Regression - BIC. 



price = -1.47e+04 + (-6.16e+01) * RoomTypePrivateRoom + (-7.45e+01) * RoomTypeSharedRoom + (-7.08e+00) * NeighbourhodGroupBrooklyn + (1.68e+01) * NeighbourhodGroupManhattan + (3.64e+00) * NeighbourhodGroupQueens + (-7.20e+01) * NeighbourhoodGroupStatenIsland + (-2.43e+02) * Longitude + (4.37e-02) * Availability_365 + (-1.92e-01) * MinimumNights + (-7.72e+01) * Latitude + (1.06e-01) * CalculatedHostListingsCount + (-2.48e-02) * NumberOfReviews + (-8.30e-02) * ReviewsPerMonth
